Hoy en día en los dispositivos que usamos comunmente tales como las computadoras, smartphones o consolas de videojuegos interactuamos con ellos mediante periféricos tales como el teclado o el ratón. Estos a pesar de estar totalmente estandarizados tienen tambien sus limitaciones en muchas aplicaciones que requieren una interacción mas natural con las manos tales como la realidad virtual o los softwares de diseño 3D. En un dispositivo que pueda cumplir la tarea de \textit{trackear} los movimientos de nuestras manos tambien se presenta el reto de que la consola con la que estemos interactuando interprete correctamente las acciones o gestos que queremos realizar y no solo el movimiento en sí. 

Aunque para nosotros reconocer tales gestos es una tarea sumamente sencilla y para la que nuestro cerebro está entrenado, para las computadoras no lo es tanto ya que nuestros movimientos no son perfectos y por tanto cada gesto aunque sea el mismo siempre dará mediciones distintas a los sensores. Por ello en este trabajo de investigación se usará el potencial del TinyML para el reconocimiento de estos gestos. El TinyML es una rama de la inteligencia artificial cuyo desarrollo está siendo muy relevante en la acualidad y que busca entrenar modelos lo suficientemente capaces y que a la vez puedan ejecutarse en procesadores de muy bajos recursos como lo son los microcontroladores.

Esta capacidad de reconocer gestos de las manos mediante un traqueo simple puede dar lugar a plicaciones tales como: Tracking de destreza y movilidad en terapias de rehabilidación médica, como input a una computadora para usarse como periferico en programas que requieran control de un entorno 3D como videojuegos y la traduccion de lenguaje de señas a texto. Esta última será la aplicación usada como demostración del uso que puede tener el diseño del sistema de reconocimiento de gestos presentado en este trabajo de tesis.
